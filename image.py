# image.py - ê°œì„ ëœ OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ
import cv2
import numpy as np
import os
try:
    import pytesseract
    # Windowsì˜ ê²½ìš° tesseract ê²½ë¡œ ì„¤ì • (í•„ìš”ì‹œ)
    # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    print("âš ï¸ pytesseractê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("   pip install pytesseract")
    print("   ê·¸ë¦¬ê³  Tesseract OCR ì—”ì§„ë„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")

class ImageProcessor:
    def __init__(self):
        print("[ì„¤ì •] ì´ë¯¸ì§€ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”")
        if not TESSERACT_AVAILABLE:
            print("âš ï¸ OCR ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def preprocess_image(self, image):
        """ê°œì„ ëœ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        print("[ì²˜ë¦¬] ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘")
        
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        
        # 3. ì ì‘ì  ì´ì§„í™” (ë” ë‚˜ì€ í…ìŠ¤íŠ¸ ë¶„ë¦¬)
        binary = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        # 4. í…ìŠ¤íŠ¸ ì˜ì—­ ê°•í™”ë¥¼ ìœ„í•œ ëª¨í´ë¡œì§€ ì—°ì‚°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        morphology = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # 5. ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
        cleaned = cv2.morphologyEx(morphology, cv2.MORPH_OPEN, kernel)
        
        return cleaned
    
    def preprocess_for_ocr(self, image):
        """OCRì„ ìœ„í•œ íŠ¹ë³„í•œ ì „ì²˜ë¦¬"""
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # 2. ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€ (OCR ì •í™•ë„ í–¥ìƒ)
        height, width = gray.shape
        scale_factor = 2 if min(height, width) < 500 else 1.5
        scaled = cv2.resize(gray, None, fx=scale_factor, fy=scale_factor, 
                          interpolation=cv2.INTER_CUBIC)
        
        # 3. ëŒ€ë¹„ ê°œì„ 
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(scaled)
        
        # 4. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (ì•½ê°„ë§Œ)
        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)
        
        # 5. ì´ì§„í™” (OCRì— ìµœì í™”)
        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def extract_text_from_region(self, image, bbox):
        """íŠ¹ì • ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        if not TESSERACT_AVAILABLE:
            return "[OCR ë¶ˆê°€] pytesseractê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
        
        x, y, w, h = bbox
        
        # ì˜ì—­ ì¶”ì¶œ (ì•½ê°„ì˜ íŒ¨ë”© ì¶”ê°€)
        padding = 5
        x_start = max(0, x - padding)
        y_start = max(0, y - padding)
        x_end = min(image.shape[1], x + w + padding)
        y_end = min(image.shape[0], y + h + padding)
        
        roi = image[y_start:y_end, x_start:x_end]
        
        if roi.size == 0:
            return ""
        
        try:
            # OCRì„ ìœ„í•œ ì „ì²˜ë¦¬
            processed_roi = self.preprocess_for_ocr(roi)
            
            # OCR ì‹¤í–‰ (í•œê¸€ê³¼ ì˜ì–´ ì§€ì›)
            config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789+-Ã—Ã·=()[]{}ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzê°€-í£ '
            text = pytesseract.image_to_string(processed_roi, lang='kor+eng', config=config)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = text.strip().replace('\n', ' ').replace('\r', '')
            cleaned_text = ' '.join(cleaned_text.split())  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            
            return cleaned_text
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"[OCR ì˜¤ë¥˜] {str(e)}"
    
    def find_text_regions_advanced(self, preprocessed, original_image):
        """ê°œì„ ëœ í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ"""
        regions = []
        
        # 1. MSER (Maximally Stable Extremal Regions) ê²€ì¶œê¸° ì‚¬ìš©
        mser = cv2.MSER_create()
        regions_mser, _ = mser.detectRegions(preprocessed)
        
        # 2. ìœ¤ê³½ì„  ê¸°ë°˜ ê²€ì¶œ
        contours, _ = cv2.findContours(
            preprocessed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        # 3. ë‘ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ í†µí•©
        all_regions = []
        
        # MSER ì˜ì—­ ì²˜ë¦¬
        for region in regions_mser:
            hull = cv2.convexHull(region.reshape(-1, 1, 2))
            x, y, w, h = cv2.boundingRect(hull)
            
            # í¬ê¸° í•„í„°ë§
            if 15 <= w <= original_image.shape[1] * 0.8 and 10 <= h <= original_image.shape[0] * 0.3:
                all_regions.append((x, y, w, h, w * h))
        
        # ìœ¤ê³½ì„  ì˜ì—­ ì²˜ë¦¬
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # í¬ê¸° í•„í„°ë§ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
            if 15 <= w <= original_image.shape[1] * 0.9 and 10 <= h <= original_image.shape[0] * 0.4:
                all_regions.append((x, y, w, h, w * h))
        
        # 4. ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_regions = []
        for region in all_regions:
            x, y, w, h, area = region
            
            # ê¸°ì¡´ ì˜ì—­ê³¼ì˜ ì¤‘ë³µ ì²´í¬
            is_duplicate = False
            for existing in unique_regions:
                ex_x, ex_y, ex_w, ex_h = existing['bbox']
                
                # IoU (Intersection over Union) ê³„ì‚°
                x1 = max(x, ex_x)
                y1 = max(y, ex_y)
                x2 = min(x + w, ex_x + ex_w)
                y2 = min(y + h, ex_y + ex_h)
                
                if x1 < x2 and y1 < y2:
                    intersection = (x2 - x1) * (y2 - y1)
                    union = area + (ex_w * ex_h) - intersection
                    iou = intersection / union if union > 0 else 0
                    
                    if iou > 0.5:  # 50% ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                unique_regions.append({
                    'bbox': (x, y, w, h),
                    'area': area
                })
        
        # 5. Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
        unique_regions.sort(key=lambda r: (r['bbox'][1], r['bbox'][0]))
        
        return unique_regions
    
    def extract_text(self, image_path):
        """ê°œì„ ëœ í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ ë° OCR - ë©”ì¸ í•¨ìˆ˜"""
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ (í•œê¸€ ê²½ë¡œ ì§€ì›)
            img_array = np.fromfile(image_path, np.uint8)
            image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            
            if image is None:
                raise Exception("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"[ì •ë³´] ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1]}x{image.shape[0]}")
            
            # ì „ì²˜ë¦¬
            preprocessed = self.preprocess_image(image)
            
            # ê²°ê³¼ ì €ì¥
            current_dir = os.path.dirname(image_path)
            processed_path = os.path.join(current_dir, "processed_problem.png")
            cv2.imwrite(processed_path, preprocessed)
            print(f"[ê²°ê³¼] ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_path}")
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ
            regions = self.find_text_regions_advanced(preprocessed, image)
            
            print(f"[ê²°ê³¼] {len(regions)}ê°œì˜ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ê²€ì¶œí–ˆìŠµë‹ˆë‹¤.")
            
            # ê° ì˜ì—­ì—ì„œ OCR ì‹¤í–‰
            ocr_results = []
            for i, region in enumerate(regions):
                bbox = region['bbox']
                text = self.extract_text_from_region(image, bbox)
                
                if text.strip():  # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                    ocr_results.append({
                        'bbox': bbox,
                        'text': text,
                        'area': region['area'],
                        'line_number': i + 1
                    })
                    print(f"[OCR {i+1}] {text}")
            
            # ê²°ê³¼ ì‹œê°í™”
            result_image = image.copy()
            for i, result in enumerate(ocr_results):
                x, y, w, h = result['bbox']
                
                # ì˜ì—­ í‘œì‹œ
                cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # ë²ˆí˜¸ í‘œì‹œ
                cv2.putText(result_image, str(result['line_number']), (x, y-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            # ì‹œê°í™” ê²°ê³¼ ì €ì¥
            detected_path = os.path.join(current_dir, "detected_regions.png")
            cv2.imwrite(detected_path, result_image)
            print(f"[ê²°ê³¼] ê²€ì¶œëœ ì˜ì—­ ì´ë¯¸ì§€: {detected_path}")
            
            return ocr_results
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def extract_math_expressions(self, ocr_results):
        """OCR ê²°ê³¼ì—ì„œ ìˆ˜ì‹ í‘œí˜„ì‹ ì •ë³´ ì¶”ì¶œ"""
        expressions = []
        all_text = ""
        
        for result in ocr_results:
            expressions.append({
                'line_number': result['line_number'],
                'region': result['bbox'],
                'area': result['area'],
                'text': result['text']
            })
            all_text += result['text'] + " "
        
        print(f"[ì •ë³´] {len(expressions)}ê°œì˜ ìˆ˜ì‹ ì˜ì—­ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")
        print(f"[ì „ì²´ í…ìŠ¤íŠ¸] {all_text.strip()}")
        
        return expressions, all_text.strip()


# í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤ (ê°„í¸ ì‚¬ìš©ìš©)
def process_image(image_path):
    """
    ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì¶”ì¶œí•˜ê³  OCRì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        list: OCR ê²°ê³¼ë“¤
        [
            {
                'bbox': (x, y, w, h),  # ì˜ì—­ ì¢Œí‘œ
                'text': str,           # ì¸ì‹ëœ í…ìŠ¤íŠ¸
                'area': int,           # ì˜ì—­ í¬ê¸°
                'line_number': int     # ì¤„ ë²ˆí˜¸
            },
            ...
        ]
    """
    processor = ImageProcessor()
    return processor.extract_text(image_path)


def get_math_regions(image_path):
    """
    ì´ë¯¸ì§€ì—ì„œ ìˆ˜í•™ í‘œí˜„ì‹ ì˜ì—­ì„ ì¶”ì¶œí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        tuple: (ìˆ˜í•™ í‘œí˜„ì‹ ì˜ì—­ë“¤ì˜ ì •ë³´, ì „ì²´ í…ìŠ¤íŠ¸)
        (
            [
                {
                    'line_number': int,      # ì¤„ ë²ˆí˜¸
                    'region': (x, y, w, h),  # ì˜ì—­ ì¢Œí‘œ
                    'area': int,             # ì˜ì—­ í¬ê¸°
                    'text': str              # ì¸ì‹ëœ í…ìŠ¤íŠ¸
                },
                ...
            ],
            str  # ì „ì²´ í…ìŠ¤íŠ¸
        )
    """
    processor = ImageProcessor()
    ocr_results = processor.extract_text(image_path)
    if ocr_results:
        return processor.extract_math_expressions(ocr_results)
    return [], ""


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    print("ê°œì„ ëœ OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    if not TESSERACT_AVAILABLE:
        print("âŒ OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:")
        print("1. pip install pytesseract")
        print("2. Tesseract OCR ì—”ì§„ ì„¤ì¹˜")
        print("   - Windows: https://github.com/UB-Mannheim/tesseract/wiki")
        print("   - Ubuntu: sudo apt install tesseract-ocr tesseract-ocr-kor")
        print("   - macOS: brew install tesseract tesseract-lang")
        print()
    
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    test_image = os.path.join(current_dir, "example.png")
    
    if not os.path.exists(test_image):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {test_image}")
        print("   example.png íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    else:
        print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {os.path.basename(test_image)}")
        
        # í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        print("\nğŸ” OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        ocr_results = process_image(test_image)
        
        if ocr_results:
            print(f"âœ… {len(ocr_results)}ê°œ ì˜ì—­ì—ì„œ OCR ì„±ê³µ!")
            for i, result in enumerate(ocr_results[:5]):  # ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
                print(f"   ì˜ì—­ {result['line_number']}: '{result['text']}'")
        else:
            print("âŒ OCR ê²°ê³¼ ì—†ìŒ")
        
        print("\nğŸ§® ìˆ˜í•™ ì˜ì—­ ë¶„ì„ í…ŒìŠ¤íŠ¸:")
        math_regions, full_text = get_math_regions(test_image)
        
        if math_regions:
            print(f"âœ… {len(math_regions)}ê°œ ìˆ˜í•™ ì˜ì—­ ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸: '{full_text}'")
            
            for region in math_regions[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
                print(f"   ì¤„ {region['line_number']}: '{region['text']}'")
        else:
            print("âŒ ìˆ˜í•™ ì˜ì—­ ë¶„ì„ ì‹¤íŒ¨")
        
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print(f"   â€¢ processed_problem.png (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€)")
        print(f"   â€¢ detected_regions.png (ê²€ì¶œëœ ì˜ì—­ í‘œì‹œ)")