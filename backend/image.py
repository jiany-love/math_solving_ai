"""image.py - ê°œì„ ëœ OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ

í•µì‹¬ ê¸°ëŠ¥:
1. ì „ì²˜ë¦¬ (ë…¸ì´ì¦ˆ ì œê±°, ëŒ€ë¹„ í–¥ìƒ, ì´ì§„í™”, ëª¨í´ë¡œì§€)ë¡œ í…ìŠ¤íŠ¸ ëŒ€ë¹„ ê·¹ëŒ€í™”
2. MSER + ìœ¤ê³½ì„  ê¸°ë°˜ì˜ í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ í›„ IoU ê¸°ë°˜ ì¤‘ë³µ ì œê±°
3. ê° ê²€ì¶œ ì˜ì—­ì— ëŒ€í•´ Tesseract OCR ì ìš© (í•œ/ì˜ í˜¼ìš© í—ˆìš©)
4. ê²€ì¶œ ê²°ê³¼ë¥¼ ì˜ì—­ ì •ë³´(list[dict])ì™€ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ êµ¬ì¡°í™” ë°˜í™˜
5. ì‹œê°í™” ì´ë¯¸ì§€(ì „ì²˜ë¦¬ ê²°ê³¼, ê²€ì¶œ ì˜ì—­ ë°•ìŠ¤)ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œê°€ í™œìš© ê°€ëŠ¥

ì£¼ìš” ì„¤ê³„ ë©”ëª¨:
- pytesseract ë¯¸ì„¤ì¹˜ í™˜ê²½ì—ì„œë„ ëª¨ë“ˆ import ìì²´ëŠ” ì‹¤íŒ¨í•˜ì§€ ì•Šë„ë¡ try/except ì²˜ë¦¬
- ê²½ëŸ‰í™” ëª©ì ìœ¼ë¡œ EasyOCR ë“± ë¬´ê±°ìš´ ì˜ì¡´ì„± ì—†ì´ Tesseract ìœ„ì£¼ ì‚¬ìš©
- ì‘ì€ ì˜ì—­ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë©´ì„œë„ ìˆ˜ì‹ ë‚´ ê¸°í˜¸ ê¹¨ì§ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì»¤ë„ í¬ê¸°ë¥¼ ì‘ê²Œ ìœ ì§€

ë°˜í™˜ ë°ì´í„° ì˜ˆì‹œ (get_math_regions):
[
    { 'line_number': 1, 'region': (x,y,w,h), 'area': int, 'text': '2x + 3' },
    ...
], "2x + 3 ..." (ì „ì²´ í…ìŠ¤íŠ¸)
"""

import cv2
import numpy as np
import os
try:
    import pytesseract
    # Windowsì˜ ê²½ìš° tesseract ê²½ë¡œ ì„¤ì • (í•„ìš”ì‹œ)
    # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    print("âš ï¸ pytesseractê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("   pip install pytesseract")
    print("   ê·¸ë¦¬ê³  Tesseract OCR ì—”ì§„ë„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")

class ImageProcessor:
    """OCR ì „ì²˜ë¦¬ + ì˜ì—­ ê²€ì¶œ + í…ìŠ¤íŠ¸ ì¶”ì¶œ ë‹´ë‹¹ í´ë˜ìŠ¤."""

    def __init__(self):
        print("[ì„¤ì •] ì´ë¯¸ì§€ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”")
        if not TESSERACT_AVAILABLE:
            print("âš ï¸ OCR ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def preprocess_image(self, image):
        """ê¸°ë³¸ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ê²€ì¶œìš©).

        Steps:
          1) Grayscale
          2) Gaussian Blur (ê²½ë¯¸í•œ ë…¸ì´ì¦ˆ ì œê±°)
          3) Adaptive Threshold (ë¶ˆê· ì¼ ì¡°ëª… ë³´ì •)
          4) Morph Close (ë¬¸ì ì˜ì—­ ë­‰ì¹¨ ê°•í™”)
          5) Morph Open (ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°)
        """
        print("[ì²˜ë¦¬] ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘")
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        # 3. ì ì‘ì  ì´ì§„í™” (ë” ë‚˜ì€ í…ìŠ¤íŠ¸ ë¶„ë¦¬)
        binary = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        # 4. í…ìŠ¤íŠ¸ ì˜ì—­ ê°•í™”ë¥¼ ìœ„í•œ ëª¨í´ë¡œì§€ ì—°ì‚°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        morphology = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        # 5. ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
        cleaned = cv2.morphologyEx(morphology, cv2.MORPH_OPEN, kernel)
        return cleaned
    
    def preprocess_for_ocr(self, image):
        """OCR ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ê³ ê¸‰ ì „ì²˜ë¦¬.

        - í¬ê¸° í™•ëŒ€: ì‘ì€ ê¸€ì ì„¸ë¶€ ì •ë³´ í™•ë³´
        - CLAHE: ì§€ì—­ ëŒ€ë¹„ í–¥ìƒ
        - Otsu Threshold: ì „ì—­ ì´ì§„í™”ë¡œ ëšœë ·í•œ ê²½ê³„ í™•ë³´
        """
        # 1. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # 2. ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€ (OCR ì •í™•ë„ í–¥ìƒ)
        height, width = gray.shape
        scale_factor = 2 if min(height, width) < 500 else 1.5
        scaled = cv2.resize(gray, None, fx=scale_factor, fy=scale_factor, 
                          interpolation=cv2.INTER_CUBIC)
        
        # 3. ëŒ€ë¹„ ê°œì„ 
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(scaled)
        
        # 4. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ (ì•½ê°„ë§Œ)
        blurred = cv2.GaussianBlur(enhanced, (1, 1), 0)
        
        # 5. ì´ì§„í™” (OCRì— ìµœì í™”)
        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def extract_text_from_region(self, image, bbox):
        """ê°œë³„ ì˜ì—­ OCR.

        bbox: (x, y, w, h)
        íŒ¨ë”©ì„ ë”í•´ ê²½ê³„ í´ë¦¬í•‘ìœ¼ë¡œ ì¸í•œ ê¸€ì ì†ì‹¤ì„ ì¤„ì¸ë‹¤.
        """
        if not TESSERACT_AVAILABLE:
            return "[OCR ë¶ˆê°€] pytesseractê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ"
        
        x, y, w, h = bbox
        
        # ì˜ì—­ ì¶”ì¶œ (ì•½ê°„ì˜ íŒ¨ë”© ì¶”ê°€)
        padding = 5
        x_start = max(0, x - padding)
        y_start = max(0, y - padding)
        x_end = min(image.shape[1], x + w + padding)
        y_end = min(image.shape[0], y + h + padding)
        
        roi = image[y_start:y_end, x_start:x_end]
        
        if roi.size == 0:
            return ""
        
        try:
            # OCRì„ ìœ„í•œ ì „ì²˜ë¦¬
            processed_roi = self.preprocess_for_ocr(roi)
            
            # OCR ì‹¤í–‰ (í•œê¸€ê³¼ ì˜ì–´ ì§€ì›)
            config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789+-Ã—Ã·=()[]{}ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzê°€-í£ '
            text = pytesseract.image_to_string(processed_roi, lang='kor+eng', config=config)
            
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_text = text.strip().replace('\n', ' ').replace('\r', '')
            cleaned_text = ' '.join(cleaned_text.split())  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
            
            return cleaned_text
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return f"[OCR ì˜¤ë¥˜] {str(e)}"
    
    def find_text_regions_advanced(self, preprocessed, original_image):
        """í•˜ì´ë¸Œë¦¬ë“œ í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ (MSER + Contours).

        - ë‘ ê¸°ë²•ì˜ í›„ë³´ë¥¼ í†µí•© í›„ IoU ê¸°ë°˜ ì¤‘ë³µ ì œê±°
        - ì§€ë‚˜ì¹˜ê²Œ í¬ê±°ë‚˜ ì‘ì€ ì˜ì—­ í•„í„°ë§
        - y, x ìˆœ ì •ë ¬ë¡œ ë¬¸ì„œ ìœ„â†’ì•„ë˜ íë¦„ ìœ ì§€
        """
        regions = []
        
        # 1. MSER (Maximally Stable Extremal Regions) ê²€ì¶œê¸° ì‚¬ìš©
        mser = cv2.MSER_create()
        regions_mser, _ = mser.detectRegions(preprocessed)
        
        # 2. ìœ¤ê³½ì„  ê¸°ë°˜ ê²€ì¶œ
        contours, _ = cv2.findContours(
            preprocessed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
        )
        
        # 3. ë‘ ë°©ë²•ì˜ ê²°ê³¼ë¥¼ í†µí•©
        all_regions = []
        
        # MSER ì˜ì—­ ì²˜ë¦¬
        for region in regions_mser:
            hull = cv2.convexHull(region.reshape(-1, 1, 2))
            x, y, w, h = cv2.boundingRect(hull)
            
            # í¬ê¸° í•„í„°ë§
            if 15 <= w <= original_image.shape[1] * 0.8 and 10 <= h <= original_image.shape[0] * 0.3:
                all_regions.append((x, y, w, h, w * h))
        
        # ìœ¤ê³½ì„  ì˜ì—­ ì²˜ë¦¬
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # í¬ê¸° í•„í„°ë§ (ë” ê´€ëŒ€í•œ ì¡°ê±´)
            if 15 <= w <= original_image.shape[1] * 0.9 and 10 <= h <= original_image.shape[0] * 0.4:
                all_regions.append((x, y, w, h, w * h))
        
        # 4. ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_regions = []
        for region in all_regions:
            x, y, w, h, area = region
            
            # ê¸°ì¡´ ì˜ì—­ê³¼ì˜ ì¤‘ë³µ ì²´í¬
            is_duplicate = False
            for existing in unique_regions:
                ex_x, ex_y, ex_w, ex_h = existing['bbox']
                
                # IoU (Intersection over Union) ê³„ì‚°
                x1 = max(x, ex_x)
                y1 = max(y, ex_y)
                x2 = min(x + w, ex_x + ex_w)
                y2 = min(y + h, ex_y + ex_h)
                
                if x1 < x2 and y1 < y2:
                    intersection = (x2 - x1) * (y2 - y1)
                    union = area + (ex_w * ex_h) - intersection
                    iou = intersection / union if union > 0 else 0
                    
                    if iou > 0.5:  # 50% ì´ìƒ ê²¹ì¹˜ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                        is_duplicate = True
                        break
            
            if not is_duplicate:
                unique_regions.append({
                    'bbox': (x, y, w, h),
                    'area': area
                })
        
        # 5. Y ì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
        unique_regions.sort(key=lambda r: (r['bbox'][1], r['bbox'][0]))
        
        return unique_regions
    
    def extract_text(self, image_path):
        """ì „ì²´ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜.

        ë°˜í™˜: OCR ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ê° í•­ëª©: bbox, text, area, line_number)
        ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìƒìœ„ í˜¸ì¶œë¶€ ì•ˆì •ì„± í™•ë³´)
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ (í•œê¸€ ê²½ë¡œ ì§€ì›)
            img_array = np.fromfile(image_path, np.uint8)
            image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
            
            if image is None:
                raise Exception("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"[ì •ë³´] ì´ë¯¸ì§€ í¬ê¸°: {image.shape[1]}x{image.shape[0]}")
            
            # ì „ì²˜ë¦¬
            preprocessed = self.preprocess_image(image)
            
            # ê²°ê³¼ ì €ì¥
            current_dir = os.path.dirname(image_path)
            processed_path = os.path.join(current_dir, "processed_problem.png")
            cv2.imwrite(processed_path, preprocessed)
            print(f"[ê²°ê³¼] ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_path}")
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ê²€ì¶œ
            regions = self.find_text_regions_advanced(preprocessed, image)
            
            print(f"[ê²°ê³¼] {len(regions)}ê°œì˜ í…ìŠ¤íŠ¸ ì˜ì—­ì„ ê²€ì¶œí–ˆìŠµë‹ˆë‹¤.")
            
            # ê° ì˜ì—­ì—ì„œ OCR ì‹¤í–‰
            ocr_results = []
            for i, region in enumerate(regions):
                bbox = region['bbox']
                text = self.extract_text_from_region(image, bbox)
                
                if text.strip():  # ë¹ˆ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                    ocr_results.append({
                        'bbox': bbox,
                        'text': text,
                        'area': region['area'],
                        'line_number': i + 1
                    })
                    print(f"[OCR {i+1}] {text}")
            
            # ê²°ê³¼ ì‹œê°í™”
            result_image = image.copy()
            for i, result in enumerate(ocr_results):
                x, y, w, h = result['bbox']
                
                # ì˜ì—­ í‘œì‹œ
                cv2.rectangle(result_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # ë²ˆí˜¸ í‘œì‹œ
                cv2.putText(result_image, str(result['line_number']), (x, y-5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            
            # ì‹œê°í™” ê²°ê³¼ ì €ì¥
            detected_path = os.path.join(current_dir, "detected_regions.png")
            cv2.imwrite(detected_path, result_image)
            print(f"[ê²°ê³¼] ê²€ì¶œëœ ì˜ì—­ ì´ë¯¸ì§€: {detected_path}")
            
            return ocr_results
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []
    
    def extract_math_expressions(self, ocr_results):
        """OCR ê²°ê³¼ì—ì„œ ìˆ˜ì‹ í‘œí˜„ì‹ ì •ë³´ ì¶”ì¶œ"""
        expressions = []
        all_text = ""
        
        for result in ocr_results:
            expressions.append({
                'line_number': result['line_number'],
                'region': result['bbox'],
                'area': result['area'],
                'text': result['text']
            })
            all_text += result['text'] + " "
        
        print(f"[ì •ë³´] {len(expressions)}ê°œì˜ ìˆ˜ì‹ ì˜ì—­ì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")
        print(f"[ì „ì²´ í…ìŠ¤íŠ¸] {all_text.strip()}")
        
        return expressions, all_text.strip()


# í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤ (ê°„í¸ ì‚¬ìš©ìš©)
def process_image(image_path):
    """íŒŒì¼ ê²½ë¡œ ë‹¨ìœ„ì˜ ê°„ë‹¨ í•¨ìˆ˜í˜• í—¬í¼.

    ë‚´ë¶€ì ìœ¼ë¡œ `ImageProcessor` ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ `extract_text` í˜¸ì¶œ.
    í…ŒìŠ¤íŠ¸/ì¬ì‚¬ìš© í¸ì˜ì„±ì„ ìœ„í•´ ì œê³µ.
    """
    processor = ImageProcessor()
    return processor.extract_text(image_path)


def get_math_regions(image_path):
    """ìˆ˜í•™(í…ìŠ¤íŠ¸) ì˜ì—­ ì •ë³´ ë° ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜.

    ë¹ˆ ê²°ê³¼ì¼ ê²½ìš° ([], "") í˜•ì‹ ë³´ì¥ â†’ í˜¸ì¶œ ì¸¡ì—ì„œ null ì²´í¬ ë¡œì§ ë‹¨ìˆœí™”.
    """
    processor = ImageProcessor()
    ocr_results = processor.extract_text(image_path)
    if ocr_results:
        return processor.extract_math_expressions(ocr_results)
    return [], ""


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    print("ê°œì„ ëœ OCR ì´ë¯¸ì§€ ì²˜ë¦¬ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*50)
    
    if not TESSERACT_AVAILABLE:
        print("âŒ OCR ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒì„ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:")
        print("1. pip install pytesseract")
        print("2. Tesseract OCR ì—”ì§„ ì„¤ì¹˜")
        print("   - Windows: https://github.com/UB-Mannheim/tesseract/wiki")
        print("   - Ubuntu: sudo apt install tesseract-ocr tesseract-ocr-kor")
        print("   - macOS: brew install tesseract tesseract-lang")
        print()
    
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
    current_dir = os.path.dirname(os.path.abspath(__file__))
    test_image = os.path.join(current_dir, "example.png")
    
    if not os.path.exists(test_image):
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {test_image}")
        print("   example.png íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    else:
        print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {os.path.basename(test_image)}")
        
        # í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
        print("\nğŸ” OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        ocr_results = process_image(test_image)
        
        if ocr_results:
            print(f"âœ… {len(ocr_results)}ê°œ ì˜ì—­ì—ì„œ OCR ì„±ê³µ!")
            for i, result in enumerate(ocr_results[:5]):  # ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
                print(f"   ì˜ì—­ {result['line_number']}: '{result['text']}'")
        else:
            print("âŒ OCR ê²°ê³¼ ì—†ìŒ")
        
        print("\nğŸ§® ìˆ˜í•™ ì˜ì—­ ë¶„ì„ í…ŒìŠ¤íŠ¸:")
        math_regions, full_text = get_math_regions(test_image)
        
        if math_regions:
            print(f"âœ… {len(math_regions)}ê°œ ìˆ˜í•™ ì˜ì—­ ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“ ì „ì²´ í…ìŠ¤íŠ¸: '{full_text}'")
            
            for region in math_regions[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
                print(f"   ì¤„ {region['line_number']}: '{region['text']}'")
        else:
            print("âŒ ìˆ˜í•™ ì˜ì—­ ë¶„ì„ ì‹¤íŒ¨")
        
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print(f"   â€¢ processed_problem.png (ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€)")
        print(f"   â€¢ detected_regions.png (ê²€ì¶œëœ ì˜ì—­ í‘œì‹œ)")